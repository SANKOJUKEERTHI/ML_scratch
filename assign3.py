# -*- coding: utf-8 -*-
"""Assign3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RNaX_7qGZ53RtgRK80nCOz7HnwvVq9CD
"""

#Sankoju Keerthi
#21GG10032

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import math

class linear_model:
  def __init__(self,features_train, features_test, target_train, target_test):
    self.flag = False
    self.gh = False
    self.features_train = features_train
    self.features_test = features_test
    self.target_train = target_train
    self.target_test = target_test
    self.w_closed = []
    self.initial_weight = [1,1,1,1,1,1,1,1,1,1,-1,1]
    self.LR_ClosedForm()

  def LR_ClosedForm(self):
    m1 = np.linalg.inv(np.matmul(self.features_train.T,self.features_train))
    m2 = np.matmul(self.features_train.T,self.target_train)
    self.w_closed = np.matmul(m1,m2)
    print(self.w_closed)
    print("RMSE : ",self.rmse(self.w_closed, self.features_test, self.target_test))


  def func(self,w,x):
    return np.dot(w,x)


  def gradient(self,w,x_train, y_train):
    m ,n= x_train.shape
    dj_dw = np.zeros(n)
    for k in range(m):
        f_wb = np.dot(x_train[k],w)
        err = (f_wb - y_train[k])
        for j in range(n):
          dj_dw[j] = dj_dw[j] +((f_wb - y_train[k])*x_train[k][j])
    dj_dw = dj_dw / m
    return dj_dw


  def gradient_decent(self,iterations, alpha,x_train, x_test, y_train, y_test):
    m ,n= x_train.shape
    flag = True
    w_history = []
    w = self.w_closed-0.000001
    for i in range(iterations):
        dj_dw= self.gradient(w,x_train,y_train)
        w = w - alpha * dj_dw
        w_history.append(w)
    return w,self.rmse(w, x_test, y_test)


  def LR_Gradient(self,x_train,x_test,y_train,y_test):
    alpha = [0.001,0.01,0.1]
    rootMSE = {}
    w_list = []
    rmse_list = []
    for a in alpha:
      d,b = self.gradient_decent(3, a,x_train, x_test, y_train, y_test)
      rootMSE[a]=[d,b]
      w_list.append(d)
      rmse_list.append(b)
    sorted_results = sorted(rootMSE.items(), key=lambda x: x[1][1])
    print(rootMSE)
    plt.plot(alpha,rmse_list,marker='o')
    plt.xlabel('Alpha (a)')
    plt.ylabel('rmse Values')
    plt.title('Alpha vs rmse')
    plt.show()
    print("The value with low rmse value is : ",list(rootMSE.items())[0])




  def rmse(self,w,x,y):
    fx = np.matmul(x,w)
    sum = 0
    m,n = x.shape
    ls = (y-fx)**2
    for l in ls:
      sum+=l
    return math.sqrt(l/m)


if __name__== '__main__' :
    df = pd.read_csv('/content/BostonHousingDataset.csv')
    dataset_altered = df.drop(columns=['LSTAT','B'])
    dataset_altered.dropna(inplace=True)
    dataset_altered = dataset_altered.astype(float)
    print(dataset_altered.head(10))

dataset_altered[['NOX', 'RM', 'AGE']].hist(bins=20, figsize=(10, 6), color='blue', alpha=0.7)
plt.suptitle('Histograms of NOX, RM, and AGE', fontsize=16)
plt.xlabel('Values')
plt.ylabel('Frequency')
plt.show()

correlation_matrix = dataset_altered.corr()
print("Correlation Coefficients:")
plt.figure(figsize=(12, 8))
print(correlation_matrix)
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

dataset_altered_features = dataset_altered.drop("MEDV", axis=1)
ones_column = np.ones((dataset_altered_features.shape[0], 1))
dataset_altered_features = np.concatenate((ones_column, dataset_altered_features), axis=1)
dataset_altered_target = dataset_altered["MEDV"]
features_train, features_test, target_train, target_test = train_test_split(
    dataset_altered_features,
    dataset_altered_target,
    test_size=0.10,
    shuffle=False,
    random_state=100
)
target_train = target_train.to_numpy()
target_test = target_test.to_numpy()
print("Shapes of Training and Testing Subsets for Features:")
print("Training Features:", features_train.shape)
print("Training target:", target_train.shape)
print("Testing Features:", features_test.shape)
print("Testing target:", target_test.shape)

solution = linear_model(features_train, features_test, target_train, target_test)

solution.LR_Gradient(features_train, features_test, target_train, target_test)

